{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d47d93",
   "metadata": {
    "papermill": {
     "duration": 0.006762,
     "end_time": "2025-04-21T14:30:20.686183",
     "exception": false,
     "start_time": "2025-04-21T14:30:20.679421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Welcome to my Kaggle inference notebook! In this notebook, I'll guide you through the process of making predictions using a model trained for the BIRDClef 2023 competition. The model has been trained using supervised contrastive learning and implemented with PyTorch Lightning.\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "- **Inference Approach:** Leveraging the trained model to make predictions on new data.\n",
    "- **Framework:** PyTorch Lightning is utilized to streamline the inference process.\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "Feel free to explore the inference code, try out predictions on different data, and adapt the model for your specific needs. If you find this notebook helpful, consider giving it an upvote to show your support.\n",
    "\n",
    "For more detailed information on the training process and model architecture, check out my [BirdCLEF23 Supervised Contrastive Loss Training](https://www.kaggle.com/code/vijayravichander/supervised-contrastive-learning-pytorchlightning).\n",
    "\n",
    "\n",
    "**Notebook Credits:**\n",
    "- This notebook builds upon the work of [Nischay Dhankhar](https://www.kaggle.com/nischaydnk/). I have adapted and extended their code for the inference phase of the BIRDClef 2023 competition.\n",
    "\n",
    "## Upvote if Useful\n",
    "\n",
    "If you find this inference notebook valuable, please consider giving it an upvote. Your feedback and support are highly appreciated!\n",
    "\n",
    "Happy predicting!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf06ac5e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:20.699170Z",
     "iopub.status.busy": "2025-04-21T14:30:20.698750Z",
     "iopub.status.idle": "2025-04-21T14:30:33.060622Z",
     "shell.execute_reply": "2025-04-21T14:30:33.059443Z"
    },
    "papermill": {
     "duration": 12.371119,
     "end_time": "2025-04-21T14:30:33.063192",
     "exception": false,
     "start_time": "2025-04-21T14:30:20.692073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torchmetrics import Metric\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "338326d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.076138Z",
     "iopub.status.busy": "2025-04-21T14:30:33.075553Z",
     "iopub.status.idle": "2025-04-21T14:30:33.082952Z",
     "shell.execute_reply": "2025-04-21T14:30:33.081912Z"
    },
    "papermill": {
     "duration": 0.016577,
     "end_time": "2025-04-21T14:30:33.085336",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.068759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_classes = 264\n",
    "    batch_size = 12\n",
    "    PRECISION = 16    \n",
    "    seed = 2023\n",
    "    model = \"resnet50\"\n",
    "    pretrained = False\n",
    "    use_mixup = False\n",
    "    mixup_alpha = 0.2   \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "\n",
    "    data_root = \"/kaggle/input/birdclef-2023/\"\n",
    "    train_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/train/\"\n",
    "    valid_images = \"/kaggle/input/split-creating-melspecs-stage-1/specs/valid/\"\n",
    "    train_path = \"/kaggle/input/bc2023-train-val-df/train.csv\"\n",
    "    valid_path = \"/kaggle/input/bc2023-train-val-df/valid.csv\"\n",
    "    \n",
    "    test_path = '/kaggle/input/birdclef-2023/test_soundscapes/'\n",
    "    SR = 32000\n",
    "    DURATION = 5\n",
    "    LR = 5e-4\n",
    "    \n",
    "    model_ckpt = '/kaggle/input/birdclef23-supervised-contrastive-loss-training/birdclef_supconmodel.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06c2ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.097835Z",
     "iopub.status.busy": "2025-04-21T14:30:33.097452Z",
     "iopub.status.idle": "2025-04-21T14:30:33.113666Z",
     "shell.execute_reply": "2025-04-21T14:30:33.112311Z"
    },
    "papermill": {
     "duration": 0.025404,
     "end_time": "2025-04-21T14:30:33.116188",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.090784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(Config.seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af81ff6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.130979Z",
     "iopub.status.busy": "2025-04-21T14:30:33.130596Z",
     "iopub.status.idle": "2025-04-21T14:30:33.136109Z",
     "shell.execute_reply": "2025-04-21T14:30:33.134884Z"
    },
    "papermill": {
     "duration": 0.014848,
     "end_time": "2025-04-21T14:30:33.138383",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.123535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def config_to_dict(cfg):\n",
    "    return dict((name, getattr(cfg, name)) for name in dir(cfg) if not name.startswith('__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4cc041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.152632Z",
     "iopub.status.busy": "2025-04-21T14:30:33.152231Z",
     "iopub.status.idle": "2025-04-21T14:30:33.163687Z",
     "shell.execute_reply": "2025-04-21T14:30:33.162511Z"
    },
    "papermill": {
     "duration": 0.021901,
     "end_time": "2025-04-21T14:30:33.166142",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.144241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_melspec(y, sr, n_mels, fmin, fmax):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} -- signal\n",
    "        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array -- Mel-spectrogram\n",
    "    \"\"\"\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax,\n",
    "    )\n",
    "\n",
    "    melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "    return melspec\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "    \n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V\n",
    "\n",
    "def crop_or_pad(y, length, is_train=True, start=None):\n",
    "    if len(y) < length:\n",
    "        y = np.concatenate([y, np.zeros(length - len(y))])\n",
    "        \n",
    "        n_repeats = length // len(y)\n",
    "        epsilon = length % len(y)\n",
    "        \n",
    "        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n",
    "        \n",
    "    elif len(y) > length:\n",
    "        if not is_train:\n",
    "            start = start or 0\n",
    "        else:\n",
    "            start = start or np.random.randint(len(y) - length)\n",
    "\n",
    "        y = y[start:start + length]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e34125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.179368Z",
     "iopub.status.busy": "2025-04-21T14:30:33.178976Z",
     "iopub.status.idle": "2025-04-21T14:30:33.380074Z",
     "shell.execute_reply": "2025-04-21T14:30:33.378896Z"
    },
    "papermill": {
     "duration": 0.211011,
     "end_time": "2025-04-21T14:30:33.382746",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.171735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(Config.train_path)\n",
    "Config.num_classes = len(df_train.primary_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7514875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.398326Z",
     "iopub.status.busy": "2025-04-21T14:30:33.397946Z",
     "iopub.status.idle": "2025-04-21T14:30:33.408303Z",
     "shell.execute_reply": "2025-04-21T14:30:33.406860Z"
    },
    "papermill": {
     "duration": 0.020424,
     "end_time": "2025-04-21T14:30:33.410687",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.390263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/birdclef-2023/test_soundscapes/soundscape_29201.ogg\n",
      "soundscape_29201\n",
      "['soundscape', '29201']\n"
     ]
    }
   ],
   "source": [
    "for path in Path(Config.test_path).glob(\"*.ogg\"):\n",
    "    print(path)\n",
    "    print(path.stem)\n",
    "    print(path.stem.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ff940c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.423802Z",
     "iopub.status.busy": "2025-04-21T14:30:33.423441Z",
     "iopub.status.idle": "2025-04-21T14:30:33.443001Z",
     "shell.execute_reply": "2025-04-21T14:30:33.441861Z"
    },
    "papermill": {
     "duration": 0.029106,
     "end_time": "2025-04-21T14:30:33.445669",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.416563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201</td>\n",
       "      <td>soundscape</td>\n",
       "      <td>29201</td>\n",
       "      <td>/kaggle/input/birdclef-2023/test_soundscapes/s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename        name     id  \\\n",
       "0  soundscape_29201  soundscape  29201   \n",
       "\n",
       "                                                path  \n",
       "0  /kaggle/input/birdclef-2023/test_soundscapes/s...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(\n",
    "     [(path.stem, *path.stem.split(\"_\"), path) for path in Path(Config.test_path).glob(\"*.ogg\")],\n",
    "    columns = [\"filename\", \"name\" ,\"id\", \"path\"]\n",
    ")\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b0e220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.459678Z",
     "iopub.status.busy": "2025-04-21T14:30:33.459296Z",
     "iopub.status.idle": "2025-04-21T14:30:33.517859Z",
     "shell.execute_reply": "2025-04-21T14:30:33.516770Z"
    },
    "papermill": {
     "duration": 0.068902,
     "end_time": "2025-04-21T14:30:33.520489",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.451587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import librosa.display as lbd\n",
    "import soundfile as sf\n",
    "from  soundfile import SoundFile \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, data, sr=Config.SR, n_mels=128, fmin=0, fmax=None, duration=Config.DURATION, step=None, res_type=\"kaiser_fast\", resample=True):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax or self.sr//2\n",
    "\n",
    "        self.duration = duration\n",
    "        self.audio_length = self.duration*self.sr\n",
    "        self.step = step or self.audio_length\n",
    "        \n",
    "        self.res_type = res_type\n",
    "        self.resample = resample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(image):\n",
    "        image = image.astype(\"float32\", copy=False) / 255.0\n",
    "        image = np.stack([image, image, image])\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def audio_to_image(self, audio):\n",
    "        melspec = compute_melspec(audio, self.sr, self.n_mels, self.fmin, self.fmax) \n",
    "        image = mono_to_color(melspec)\n",
    "        image = self.normalize(image)\n",
    "        return image\n",
    "\n",
    "    def read_file(self, filepath):\n",
    "        audio, orig_sr = sf.read(filepath, dtype=\"float32\")\n",
    "\n",
    "        if self.resample and orig_sr != self.sr:\n",
    "            audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n",
    "          \n",
    "        audios = []\n",
    "        for i in range(self.audio_length, len(audio) + self.step, self.step):\n",
    "            start = max(0, i - self.audio_length)\n",
    "            end = start + self.audio_length\n",
    "            audios.append(audio[start:end])\n",
    "            \n",
    "        if len(audios[-1]) < self.audio_length:\n",
    "            audios = audios[:-1]\n",
    "            \n",
    "        images = [self.audio_to_image(audio) for audio in audios]\n",
    "        images = np.stack(images)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.read_file(self.data.loc[idx, \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959e1808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.533492Z",
     "iopub.status.busy": "2025-04-21T14:30:33.533121Z",
     "iopub.status.idle": "2025-04-21T14:30:33.540146Z",
     "shell.execute_reply": "2025-04-21T14:30:33.539083Z"
    },
    "papermill": {
     "duration": 0.016354,
     "end_time": "2025-04-21T14:30:33.542634",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.526280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = BirdDataset(\n",
    "    df_test, \n",
    "    sr = Config.SR,\n",
    "    duration = Config.DURATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25fa97f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:33.557556Z",
     "iopub.status.busy": "2025-04-21T14:30:33.557211Z",
     "iopub.status.idle": "2025-04-21T14:30:51.485153Z",
     "shell.execute_reply": "2025-04-21T14:30:51.483915Z"
    },
    "papermill": {
     "duration": 17.943954,
     "end_time": "2025-04-21T14:30:51.492783",
     "exception": false,
     "start_time": "2025-04-21T14:30:33.548829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3, 128, 313)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef7c69d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.520485Z",
     "iopub.status.busy": "2025-04-21T14:30:51.519684Z",
     "iopub.status.idle": "2025-04-21T14:30:51.820955Z",
     "shell.execute_reply": "2025-04-21T14:30:51.819746Z"
    },
    "papermill": {
     "duration": 0.316828,
     "end_time": "2025-04-21T14:30:51.823334",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.506506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission#.drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f571ed13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.839079Z",
     "iopub.status.busy": "2025-04-21T14:30:51.838700Z",
     "iopub.status.idle": "2025-04-21T14:30:51.857582Z",
     "shell.execute_reply": "2025-04-21T14:30:51.856435Z"
    },
    "papermill": {
     "duration": 0.030378,
     "end_time": "2025-04-21T14:30:51.860555",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.830177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SupConLoss: https://github.com/HobbitLong/SupContrast/blob/master/losses.py\n",
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        # modified to handle edge cases when there is no positive pair\n",
    "        # for an anchor point.\n",
    "        # Edge case e.g.:-\n",
    "        # features of shape: [4,1,...]\n",
    "        # labels:            [0,1,1,2]\n",
    "        # loss before mean:  [nan, ..., ..., nan]\n",
    "        mask_pos_pairs = mask.sum(1)\n",
    "        mask_pos_pairs = torch.where(mask_pos_pairs < 1e-6, 1, mask_pos_pairs)\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask_pos_pairs\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e87e1613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.875451Z",
     "iopub.status.busy": "2025-04-21T14:30:51.875001Z",
     "iopub.status.idle": "2025-04-21T14:30:51.887318Z",
     "shell.execute_reply": "2025-04-21T14:30:51.885998Z"
    },
    "papermill": {
     "duration": 0.022909,
     "end_time": "2025-04-21T14:30:51.890010",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.867101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(pl.LightningModule):\n",
    "    def __init__(self, model_name, emb_dim):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\"resnet50\", pretrained = False)\n",
    "        self.in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(self.in_features, emb_dim)\n",
    "        self.loss_fn = SupConLoss(0.07, 'one', 0.07)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.backbone(x)\n",
    "        return emb\n",
    "\n",
    "    # Difference between Normal and Lightning: The train, valid and test steps is written here inside the class\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "\n",
    "        bsz = len(labels)\n",
    "\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "\n",
    "        #print(images.shape)\n",
    "\n",
    "        features = self.forward(images)\n",
    "\n",
    "        # Manipulating the features for SupConLoss\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # Calculating SupConLoss\n",
    "        loss = self.loss_fn(features,labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # We have training_epoch_end function\n",
    "    # def on_train_epoch_end(self):\n",
    "    #     #print(\"Epoch Done\")\n",
    "\n",
    "    def validation_step(self, batch , batch_idx):\n",
    "\n",
    "        images, labels = batch\n",
    "\n",
    "        bsz = len(labels)\n",
    "\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "        \n",
    "        #print(images.shape)\n",
    "\n",
    "        features = self.forward(images)\n",
    "\n",
    "        # Manipulating the arrangment of features for SupConLoss\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # Calculating SupConLoss\n",
    "        loss = self.loss_fn(features,labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        \n",
    "        bsz = len(labels)\n",
    "\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "        \n",
    "\n",
    "        features = self.forward(images)\n",
    "\n",
    "        # Manipulating the arrangment of features for SupConLoss\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "\n",
    "        # Calculating SupConLoss\n",
    "        loss = self.loss_fn(features,labels)\n",
    "        return loss\n",
    "\n",
    "    # We can add schedulers to this method\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45ee623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.904711Z",
     "iopub.status.busy": "2025-04-21T14:30:51.904225Z",
     "iopub.status.idle": "2025-04-21T14:30:51.920046Z",
     "shell.execute_reply": "2025-04-21T14:30:51.918555Z"
    },
    "papermill": {
     "duration": 0.026745,
     "end_time": "2025-04-21T14:30:51.922541",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.895796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "\n",
    "class SupConCE(pl.LightningModule):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.accuracy = torchmetrics.Accuracy(task = 'multiclass', num_classes = 264)\n",
    "        self.f1_score = torchmetrics.F1Score(task = 'multiclass', num_classes = 264)\n",
    "        backbone = 'resnet50'\n",
    "        model_path = '/kaggle/input/birdclef23-supervised-contrastive-loss-training/birdclef_supconencoder.ckpt'\n",
    "        pretrained_model = Encoder.load_from_checkpoint(model_path, model_name = backbone, emb_dim = 128)\n",
    "\n",
    "\n",
    "        #Freezing all the encoder layers\n",
    "        for param in pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "        #Trainging only the last layer\n",
    "        pretrained_model.backbone.fc = nn.Linear(in_features=pretrained_model.backbone.fc.in_features, out_features=264)\n",
    "\n",
    "        pretrained_model.backbone.fc.requires_grad = True\n",
    "\n",
    "        self.model = pretrained_model\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        y_pred = self.forward(images)\n",
    "        loss = self.loss_fn(y_pred,labels)\n",
    "        accuracy = self.accuracy(y_pred,labels)\n",
    "        f1_score = self.f1_score(y_pred,labels)\n",
    "        self.log_dict({'train_loss': loss, 'train_accuracy': accuracy, 'train_f1_score': f1_score},\n",
    "                      on_step = False, on_epoch = True, prog_bar = True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        y_pred = self.forward(images)\n",
    "        loss = self.loss_fn(y_pred,labels)\n",
    "        accuracy = self.accuracy(y_pred,labels)\n",
    "        f1_score = self.f1_score(y_pred,labels)\n",
    "        \n",
    "        one_hot_target = F.one_hot(labels, num_classes=264)\n",
    "        \n",
    "        y_pred = pd.DataFrame(y_pred.cpu().detach().numpy())\n",
    "        y_true = pd.DataFrame(one_hot_target.cpu().detach().numpy())\n",
    "        \n",
    "        cmap_score = padded_cmap(y_true, y_pred)\n",
    "        \n",
    "        self.log_dict({'valid_loss': loss, 'valid_accuracy': accuracy, 'valid_f1_score': f1_score, 'cmap_score': cmap_score},\n",
    "                      on_step = False, on_epoch = True, prog_bar = True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c778940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.939696Z",
     "iopub.status.busy": "2025-04-21T14:30:51.939322Z",
     "iopub.status.idle": "2025-04-21T14:30:51.946834Z",
     "shell.execute_reply": "2025-04-21T14:30:51.945711Z"
    },
    "papermill": {
     "duration": 0.01856,
     "end_time": "2025-04-21T14:30:51.949188",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.930628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "        \n",
    "    model.to('cpu')\n",
    "    model.eval()    \n",
    "    predictions = []\n",
    "    for en in range(len(ds_test)):\n",
    "        print(en)\n",
    "        images = torch.from_numpy(ds_test[en])\n",
    "        print(images.shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images).sigmoid().detach().cpu().numpy()\n",
    "            print(outputs.shape)\n",
    "#             pred_batch.extend(outputs.detach().cpu().numpy())\n",
    "#         pred_batch = np.vstack(pred_batch)\n",
    "        predictions.append(outputs)\n",
    "            \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bd9562e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:30:51.964239Z",
     "iopub.status.busy": "2025-04-21T14:30:51.963734Z",
     "iopub.status.idle": "2025-04-21T14:31:15.748561Z",
     "shell.execute_reply": "2025-04-21T14:31:15.747327Z"
    },
    "papermill": {
     "duration": 23.795041,
     "end_time": "2025-04-21T14:31:15.751201",
     "exception": false,
     "start_time": "2025-04-21T14:30:51.956160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Dataloader...\n",
      "Model Creation\n",
      "Running Inference..\n",
      "0\n",
      "torch.Size([120, 3, 128, 313])\n",
      "(120, 264)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "print(f\"Create Dataloader...\")\n",
    "\n",
    "ds_test = BirdDataset(\n",
    "    df_test, \n",
    "    sr = Config.SR,\n",
    "    duration = Config.DURATION,\n",
    ")\n",
    "\n",
    "\n",
    "audio_model = SupConCE()\n",
    "\n",
    "print(\"Model Creation\")\n",
    "\n",
    "model = SupConCE.load_from_checkpoint(Config.model_ckpt, train_dataloader=None,validation_dataloader=None) \n",
    "print(\"Running Inference..\")\n",
    "\n",
    "preds = predict(ds_test, model)   \n",
    "\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b41ac91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:31:15.766309Z",
     "iopub.status.busy": "2025-04-21T14:31:15.765935Z",
     "iopub.status.idle": "2025-04-21T14:31:15.809169Z",
     "shell.execute_reply": "2025-04-21T14:31:15.807861Z"
    },
    "papermill": {
     "duration": 0.053649,
     "end_time": "2025-04-21T14:31:15.811970",
     "exception": false,
     "start_time": "2025-04-21T14:31:15.758321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames = df_test.filename.values.tolist()\n",
    "\n",
    "bird_cols = list(pd.get_dummies(df_train['primary_label']).columns)\n",
    "sub_df = pd.DataFrame(columns=['row_id']+bird_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfde7894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:31:15.826144Z",
     "iopub.status.busy": "2025-04-21T14:31:15.825739Z",
     "iopub.status.idle": "2025-04-21T14:31:15.839835Z",
     "shell.execute_reply": "2025-04-21T14:31:15.838565Z"
    },
    "papermill": {
     "duration": 0.025907,
     "end_time": "2025-04-21T14:31:15.843995",
     "exception": false,
     "start_time": "2025-04-21T14:31:15.818088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, abethr1, abhori1, abythr1, afbfly1, afdfly1, afecuc1, affeag1, afgfly1, afghor1, afmdov1, afpfly1, afpkin1, afpwag1, afrgos1, afrgrp1, afrjac1, afrthr1, amesun2, augbuz1, bagwea1, barswa, bawhor2, bawman1, bcbeat1, beasun2, bkctch1, bkfruw1, blacra1, blacuc1, blakit1, blaplo1, blbpuf2, blcapa2, blfbus1, blhgon1, blhher1, blksaw1, blnmou1, blnwea1, bltapa1, bltbar1, bltori1, blwlap1, brcale1, brcsta1, brctch1, brcwea1, brican1, brobab1, broman1, brosun1, brrwhe3, brtcha1, brubru1, brwwar1, bswdov1, btweye2, bubwar2, butapa1, cabgre1, carcha1, carwoo1, categr, ccbeat1, chespa1, chewea1, chibat1, chtapa3, chucis1, cibwar1, cohmar1, colsun2, combul2, combuz1, comsan, crefra2, crheag1, crohor1, darbar1, darter3, didcuc1, dotbar1, dutdov1, easmog1, eaywag1, edcsun3, egygoo, equaka1, eswdov1, eubeat1, fatrav1, fatwid1, fislov1, fotdro5, gabgos2, gargan, gbesta1, gnbcam2, gnhsun1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 265 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57fa5c40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:31:15.858970Z",
     "iopub.status.busy": "2025-04-21T14:31:15.858583Z",
     "iopub.status.idle": "2025-04-21T14:31:15.928933Z",
     "shell.execute_reply": "2025-04-21T14:31:15.927544Z"
    },
    "papermill": {
     "duration": 0.081054,
     "end_time": "2025-04-21T14:31:15.932038",
     "exception": false,
     "start_time": "2025-04-21T14:31:15.850984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, file in enumerate(filenames):\n",
    "    pred = preds[i]\n",
    "    num_rows = len(pred)\n",
    "    row_ids = [f'{file}_{(i+1)*5}' for i in range(num_rows)]\n",
    "    df = pd.DataFrame(columns=['row_id']+bird_cols)\n",
    "    \n",
    "    df['row_id'] = row_ids\n",
    "    df[bird_cols] = pred\n",
    "    \n",
    "    sub_df = pd.concat([sub_df,df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe1c5fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:31:15.947476Z",
     "iopub.status.busy": "2025-04-21T14:31:15.947115Z",
     "iopub.status.idle": "2025-04-21T14:31:15.976219Z",
     "shell.execute_reply": "2025-04-21T14:31:15.974842Z"
    },
    "papermill": {
     "duration": 0.040564,
     "end_time": "2025-04-21T14:31:15.979134",
     "exception": false,
     "start_time": "2025-04-21T14:31:15.938570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>abethr1</th>\n",
       "      <th>abhori1</th>\n",
       "      <th>abythr1</th>\n",
       "      <th>afbfly1</th>\n",
       "      <th>afdfly1</th>\n",
       "      <th>afecuc1</th>\n",
       "      <th>affeag1</th>\n",
       "      <th>afgfly1</th>\n",
       "      <th>afghor1</th>\n",
       "      <th>...</th>\n",
       "      <th>yebsto1</th>\n",
       "      <th>yeccan1</th>\n",
       "      <th>yefcan</th>\n",
       "      <th>yelbis1</th>\n",
       "      <th>yenspu1</th>\n",
       "      <th>yertin1</th>\n",
       "      <th>yesbar1</th>\n",
       "      <th>yespet1</th>\n",
       "      <th>yetgre1</th>\n",
       "      <th>yewgre1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_29201_5</td>\n",
       "      <td>0.116512</td>\n",
       "      <td>0.486873</td>\n",
       "      <td>0.221110</td>\n",
       "      <td>0.108897</td>\n",
       "      <td>0.141980</td>\n",
       "      <td>0.448480</td>\n",
       "      <td>0.248293</td>\n",
       "      <td>0.065470</td>\n",
       "      <td>0.317077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042799</td>\n",
       "      <td>0.092287</td>\n",
       "      <td>0.330881</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.070450</td>\n",
       "      <td>0.331963</td>\n",
       "      <td>0.148679</td>\n",
       "      <td>0.077690</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.308250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_29201_10</td>\n",
       "      <td>0.108313</td>\n",
       "      <td>0.438715</td>\n",
       "      <td>0.168393</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.140094</td>\n",
       "      <td>0.309722</td>\n",
       "      <td>0.181847</td>\n",
       "      <td>0.072033</td>\n",
       "      <td>0.256558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040199</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.289637</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>0.322505</td>\n",
       "      <td>0.186693</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>0.120204</td>\n",
       "      <td>0.355694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_29201_15</td>\n",
       "      <td>0.093974</td>\n",
       "      <td>0.443084</td>\n",
       "      <td>0.158783</td>\n",
       "      <td>0.110130</td>\n",
       "      <td>0.152376</td>\n",
       "      <td>0.289842</td>\n",
       "      <td>0.150401</td>\n",
       "      <td>0.059359</td>\n",
       "      <td>0.231050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028960</td>\n",
       "      <td>0.078402</td>\n",
       "      <td>0.335150</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>0.072027</td>\n",
       "      <td>0.289389</td>\n",
       "      <td>0.121722</td>\n",
       "      <td>0.062568</td>\n",
       "      <td>0.117638</td>\n",
       "      <td>0.349231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_29201_20</td>\n",
       "      <td>0.080284</td>\n",
       "      <td>0.396208</td>\n",
       "      <td>0.160661</td>\n",
       "      <td>0.090708</td>\n",
       "      <td>0.144032</td>\n",
       "      <td>0.317586</td>\n",
       "      <td>0.147881</td>\n",
       "      <td>0.054339</td>\n",
       "      <td>0.256036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030070</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>0.263067</td>\n",
       "      <td>0.109669</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.378192</td>\n",
       "      <td>0.173363</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.130113</td>\n",
       "      <td>0.364682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_29201_25</td>\n",
       "      <td>0.072329</td>\n",
       "      <td>0.405682</td>\n",
       "      <td>0.160326</td>\n",
       "      <td>0.093747</td>\n",
       "      <td>0.139988</td>\n",
       "      <td>0.289339</td>\n",
       "      <td>0.155905</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.250272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029871</td>\n",
       "      <td>0.067345</td>\n",
       "      <td>0.259732</td>\n",
       "      <td>0.102150</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.363059</td>\n",
       "      <td>0.158101</td>\n",
       "      <td>0.048004</td>\n",
       "      <td>0.121325</td>\n",
       "      <td>0.359326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>soundscape_29201_580</td>\n",
       "      <td>0.094184</td>\n",
       "      <td>0.442897</td>\n",
       "      <td>0.164040</td>\n",
       "      <td>0.101331</td>\n",
       "      <td>0.123445</td>\n",
       "      <td>0.330819</td>\n",
       "      <td>0.193017</td>\n",
       "      <td>0.076326</td>\n",
       "      <td>0.270582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042027</td>\n",
       "      <td>0.089088</td>\n",
       "      <td>0.299949</td>\n",
       "      <td>0.118005</td>\n",
       "      <td>0.080302</td>\n",
       "      <td>0.415624</td>\n",
       "      <td>0.190539</td>\n",
       "      <td>0.069475</td>\n",
       "      <td>0.133748</td>\n",
       "      <td>0.369931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>soundscape_29201_585</td>\n",
       "      <td>0.092127</td>\n",
       "      <td>0.487067</td>\n",
       "      <td>0.177787</td>\n",
       "      <td>0.075549</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.408159</td>\n",
       "      <td>0.363001</td>\n",
       "      <td>0.071480</td>\n",
       "      <td>0.339741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>0.070842</td>\n",
       "      <td>0.216265</td>\n",
       "      <td>0.122024</td>\n",
       "      <td>0.075390</td>\n",
       "      <td>0.495463</td>\n",
       "      <td>0.249422</td>\n",
       "      <td>0.063011</td>\n",
       "      <td>0.110742</td>\n",
       "      <td>0.302326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>soundscape_29201_590</td>\n",
       "      <td>0.104662</td>\n",
       "      <td>0.474614</td>\n",
       "      <td>0.145501</td>\n",
       "      <td>0.094664</td>\n",
       "      <td>0.113486</td>\n",
       "      <td>0.333757</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>0.064747</td>\n",
       "      <td>0.287721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.284637</td>\n",
       "      <td>0.111782</td>\n",
       "      <td>0.074133</td>\n",
       "      <td>0.453096</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>0.056779</td>\n",
       "      <td>0.117621</td>\n",
       "      <td>0.321142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soundscape_29201_595</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.455230</td>\n",
       "      <td>0.184173</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.164138</td>\n",
       "      <td>0.361917</td>\n",
       "      <td>0.220704</td>\n",
       "      <td>0.079649</td>\n",
       "      <td>0.298316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045942</td>\n",
       "      <td>0.100151</td>\n",
       "      <td>0.327359</td>\n",
       "      <td>0.140731</td>\n",
       "      <td>0.094493</td>\n",
       "      <td>0.418152</td>\n",
       "      <td>0.216805</td>\n",
       "      <td>0.067450</td>\n",
       "      <td>0.132713</td>\n",
       "      <td>0.344489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>soundscape_29201_600</td>\n",
       "      <td>0.068152</td>\n",
       "      <td>0.447508</td>\n",
       "      <td>0.109855</td>\n",
       "      <td>0.061685</td>\n",
       "      <td>0.091912</td>\n",
       "      <td>0.315826</td>\n",
       "      <td>0.182206</td>\n",
       "      <td>0.037498</td>\n",
       "      <td>0.240412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017066</td>\n",
       "      <td>0.047955</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.353598</td>\n",
       "      <td>0.133467</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.075175</td>\n",
       "      <td>0.260645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   row_id   abethr1   abhori1   abythr1   afbfly1   afdfly1  \\\n",
       "0      soundscape_29201_5  0.116512  0.486873  0.221110  0.108897  0.141980   \n",
       "1     soundscape_29201_10  0.108313  0.438715  0.168393  0.105839  0.140094   \n",
       "2     soundscape_29201_15  0.093974  0.443084  0.158783  0.110130  0.152376   \n",
       "3     soundscape_29201_20  0.080284  0.396208  0.160661  0.090708  0.144032   \n",
       "4     soundscape_29201_25  0.072329  0.405682  0.160326  0.093747  0.139988   \n",
       "..                    ...       ...       ...       ...       ...       ...   \n",
       "115  soundscape_29201_580  0.094184  0.442897  0.164040  0.101331  0.123445   \n",
       "116  soundscape_29201_585  0.092127  0.487067  0.177787  0.075549  0.105394   \n",
       "117  soundscape_29201_590  0.104662  0.474614  0.145501  0.094664  0.113486   \n",
       "118  soundscape_29201_595  0.125926  0.455230  0.184173  0.122362  0.164138   \n",
       "119  soundscape_29201_600  0.068152  0.447508  0.109855  0.061685  0.091912   \n",
       "\n",
       "      afecuc1   affeag1   afgfly1   afghor1  ...   yebsto1   yeccan1  \\\n",
       "0    0.448480  0.248293  0.065470  0.317077  ...  0.042799  0.092287   \n",
       "1    0.309722  0.181847  0.072033  0.256558  ...  0.040199  0.084153   \n",
       "2    0.289842  0.150401  0.059359  0.231050  ...  0.028960  0.078402   \n",
       "3    0.317586  0.147881  0.054339  0.256036  ...  0.030070  0.066960   \n",
       "4    0.289339  0.155905  0.055040  0.250272  ...  0.029871  0.067345   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "115  0.330819  0.193017  0.076326  0.270582  ...  0.042027  0.089088   \n",
       "116  0.408159  0.363001  0.071480  0.339741  ...  0.035309  0.070842   \n",
       "117  0.333757  0.263263  0.064747  0.287721  ...  0.034777  0.076300   \n",
       "118  0.361917  0.220704  0.079649  0.298316  ...  0.045942  0.100151   \n",
       "119  0.315826  0.182206  0.037498  0.240412  ...  0.017066  0.047955   \n",
       "\n",
       "       yefcan   yelbis1   yenspu1   yertin1   yesbar1   yespet1   yetgre1  \\\n",
       "0    0.330881  0.111765  0.070450  0.331963  0.148679  0.077690  0.110651   \n",
       "1    0.289637  0.131074  0.079855  0.322505  0.186693  0.071130  0.120204   \n",
       "2    0.335150  0.104402  0.072027  0.289389  0.121722  0.062568  0.117638   \n",
       "3    0.263067  0.109669  0.068198  0.378192  0.173363  0.052080  0.130113   \n",
       "4    0.259732  0.102150  0.063694  0.363059  0.158101  0.048004  0.121325   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "115  0.299949  0.118005  0.080302  0.415624  0.190539  0.069475  0.133748   \n",
       "116  0.216265  0.122024  0.075390  0.495463  0.249422  0.063011  0.110742   \n",
       "117  0.284637  0.111782  0.074133  0.453096  0.211300  0.056779  0.117621   \n",
       "118  0.327359  0.140731  0.094493  0.418152  0.216805  0.067450  0.132713   \n",
       "119  0.248100  0.074410  0.044759  0.353598  0.133467  0.030556  0.075175   \n",
       "\n",
       "      yewgre1  \n",
       "0    0.308250  \n",
       "1    0.355694  \n",
       "2    0.349231  \n",
       "3    0.364682  \n",
       "4    0.359326  \n",
       "..        ...  \n",
       "115  0.369931  \n",
       "116  0.302326  \n",
       "117  0.321142  \n",
       "118  0.344489  \n",
       "119  0.260645  \n",
       "\n",
       "[120 rows x 265 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86edaffc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-21T14:31:15.995004Z",
     "iopub.status.busy": "2025-04-21T14:31:15.994622Z",
     "iopub.status.idle": "2025-04-21T14:31:16.037317Z",
     "shell.execute_reply": "2025-04-21T14:31:16.036255Z"
    },
    "papermill": {
     "duration": 0.053331,
     "end_time": "2025-04-21T14:31:16.039746",
     "exception": false,
     "start_time": "2025-04-21T14:31:15.986415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8776df5",
   "metadata": {
    "papermill": {
     "duration": 0.006338,
     "end_time": "2025-04-21T14:31:16.052794",
     "exception": false,
     "start_time": "2025-04-21T14:31:16.046456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5188730,
     "sourceId": 44224,
     "sourceType": "competition"
    },
    {
     "datasetId": 2991134,
     "sourceId": 5148212,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 160017136,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 211626007,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 62.044701,
   "end_time": "2025-04-21T14:31:18.645267",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-21T14:30:16.600566",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
