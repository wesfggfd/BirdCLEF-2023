{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":44224,"databundleVersionId":5188730,"sourceType":"competition"},{"sourceId":3836,"sourceType":"modelInstanceVersion","modelInstanceId":2739,"modelId":319}],"dockerImageVersionId":30407,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, we'll use a pre-trained machine learning model to generate a submission to the [BirdClef2023 competition](https://www.kaggle.com/c/birdclef-2023).  The goal of the competition is to identify Eastern African bird species by sound.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_io as tfio\n\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport glob\n\nimport csv\nimport io\n\nfrom IPython.display import Audio","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-04-15T10:26:04.725058Z","iopub.execute_input":"2025-04-15T10:26:04.725463Z","iopub.status.idle":"2025-04-15T10:26:14.885799Z","shell.execute_reply.started":"2025-04-15T10:26:04.725421Z","shell.execute_reply":"2025-04-15T10:26:14.884707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 2: Explore the training data\n\nWe'll start by loading a couple of training examples and using the IPython.display.Audio module to play them!","metadata":{}},{"cell_type":"code","source":"# Load a sample audio files from two different species\naudio_abe, sr_abe = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\")\naudio_abh, sr_abh = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\")","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:27:17.374664Z","iopub.execute_input":"2025-04-15T10:27:17.375114Z","iopub.status.idle":"2025-04-15T10:27:29.616934Z","shell.execute_reply.started":"2025-04-15T10:27:17.375072Z","shell.execute_reply":"2025-04-15T10:27:29.615588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Play the audio\nAudio(data=audio_abe, rate=sr_abe)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:28:26.075242Z","iopub.execute_input":"2025-04-15T10:28:26.076136Z","iopub.status.idle":"2025-04-15T10:28:26.157288Z","shell.execute_reply.started":"2025-04-15T10:28:26.076096Z","shell.execute_reply":"2025-04-15T10:28:26.155802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Play the audio\nAudio(data=audio_abh, rate=sr_abh)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:28:46.948524Z","iopub.execute_input":"2025-04-15T10:28:46.949434Z","iopub.status.idle":"2025-04-15T10:28:47.016664Z","shell.execute_reply.started":"2025-04-15T10:28:46.949380Z","shell.execute_reply":"2025-04-15T10:28:47.015086Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: Match the model's output with the bird species in the competition\n\nThe competition includes 264 classes of birds, 261 of which exist in this model. We'll set up a way to map the model's output logits to our competition.","metadata":{}},{"cell_type":"code","source":"model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1')\nlabels_path = hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1') + \"/assets/label.csv\"","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:30:37.786871Z","iopub.execute_input":"2025-04-15T10:30:37.787294Z","iopub.status.idle":"2025-04-15T10:30:44.351464Z","shell.execute_reply.started":"2025-04-15T10:30:37.787256Z","shell.execute_reply":"2025-04-15T10:30:44.349913Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find the name of the class with the top score when mean-aggregated across frames.\ndef class_names_from_csv(class_map_csv_text):\n    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n    with open(labels_path) as csv_file:\n        csv_reader = csv.reader(csv_file, delimiter=',')\n        class_names = [mid for mid, desc in csv_reader]\n        return class_names[1:]\n\n## note that the bird classifier classifies a much larger set of birds than the\n## competition, so we need to load the model's set of class names or else our \n## indices will be off.\nclasses = class_names_from_csv(labels_path)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:31:37.974901Z","iopub.execute_input":"2025-04-15T10:31:37.975821Z","iopub.status.idle":"2025-04-15T10:31:37.995182Z","shell.execute_reply.started":"2025-04-15T10:31:37.975774Z","shell.execute_reply":"2025-04-15T10:31:37.993673Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\")\ntrain_metadata.head()\ncompetition_classes = sorted(train_metadata.primary_label.unique())\n\nforced_defaults = 0\ncompetition_class_map = []\nfor c in competition_classes:\n    try:\n        i = classes.index(c)\n        competition_class_map.append(i)\n    except:\n        competition_class_map.append(0)\n        forced_defaults += 1\n        \n## this is the count of classes not supported by our pretrained model\n## you could choose to simply not predict these, set a default as above,\n## or create your own model using the pretrained model as a base.\nforced_defaults","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:33:38.758100Z","iopub.execute_input":"2025-04-15T10:33:38.759303Z","iopub.status.idle":"2025-04-15T10:33:38.936584Z","shell.execute_reply.started":"2025-04-15T10:33:38.759256Z","shell.execute_reply":"2025-04-15T10:33:38.935227Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Preprocess the data\n\nThe following functions are one way to load the audio provided and break it up into the five-second samples with a sample rate of 32,000 required by the competition.","metadata":{}},{"cell_type":"code","source":"def frame_audio(\n      audio_array: np.ndarray,\n      window_size_s: float = 5.0,\n      hop_size_s: float = 5.0,\n      sample_rate = 32000,\n      ) -> np.ndarray:\n    \n    \"\"\"Helper function for framing audio for inference.\"\"\"\n    \"\"\" using tf.signal \"\"\"\n    if window_size_s is None or window_size_s < 0:\n        return audio_array[np.newaxis, :]\n    frame_length = int(window_size_s * sample_rate)\n    hop_length = int(hop_size_s * sample_rate)\n    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n    return framed_audio\n\ndef ensure_sample_rate(waveform, original_sample_rate,\n                       desired_sample_rate=32000):\n    \"\"\"Resample waveform if required.\"\"\"\n    if original_sample_rate != desired_sample_rate:\n        waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n    return desired_sample_rate, waveform","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:38:30.332899Z","iopub.execute_input":"2025-04-15T10:38:30.333905Z","iopub.status.idle":"2025-04-15T10:38:30.342096Z","shell.execute_reply.started":"2025-04-15T10:38:30.333862Z","shell.execute_reply":"2025-04-15T10:38:30.340926Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Below we load one training sample - use the Audio function to listen to the samples inside the notebook!","metadata":{}},{"cell_type":"code","source":"audio, sample_rate = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/afghor1/XC156639.ogg\")\nsample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\nAudio(wav_data, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:38:41.199208Z","iopub.execute_input":"2025-04-15T10:38:41.199630Z","iopub.status.idle":"2025-04-15T10:38:41.973009Z","shell.execute_reply.started":"2025-04-15T10:38:41.199593Z","shell.execute_reply":"2025-04-15T10:38:41.971445Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 5: Make predictions\n\nEach test sample is cut into 5-second chunks. We use the pretrained model to return probabilities for all 10k birds included in the model, then pull out the classes used in this competition to create a final submission row. Note that we are NOT doing anything special to handle the 3 missing classes.","metadata":{}},{"cell_type":"code","source":"fixed_tm = frame_audio(wav_data)\nlogits, embeddings = model.infer_tf(fixed_tm[:1])\nprobabilities = tf.nn.softmax(logits)\nargmax = np.argmax(probabilities)\nprint(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:44:28.662228Z","iopub.execute_input":"2025-04-15T10:44:28.662719Z","iopub.status.idle":"2025-04-15T10:44:39.388426Z","shell.execute_reply.started":"2025-04-15T10:44:28.662680Z","shell.execute_reply":"2025-04-15T10:44:39.387068Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n    \n    audio, sample_rate = librosa.load(filename)\n    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n    \n    fixed_tm = frame_audio(wav_data)\n    \n    frame = 5\n    all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n    for window in fixed_tm[1:]:\n        if frame_limit_secs and frame > frame_limit_secs:\n            continue\n        \n        logits, embeddings = model.infer_tf(window[np.newaxis, :])\n        all_logits = np.concatenate([all_logits, logits], axis=0)\n        frame += 5\n    \n    frame = 5\n    #all_probabilities = []\n    for frame_logits in all_logits:\n        probabilities = tf.nn.softmax(frame_logits).numpy()\n        \n        ## set the appropriate row in the sample submission\n        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame), competition_classes] = probabilities[competition_class_map]\n        frame += 5","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:53:27.840096Z","iopub.execute_input":"2025-04-15T10:53:27.840577Z","iopub.status.idle":"2025-04-15T10:53:27.850159Z","shell.execute_reply.started":"2025-04-15T10:53:27.840536Z","shell.execute_reply":"2025-04-15T10:53:27.848765Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: Generate a submission\n\nNow we process all of the test samples as discussed above, creating output rows, and saving them in the provided `sample_submission.csv`. Finally, we save these rows to our final output file: `submission.csv`. This is the file that gets submitted and scored when you submit the notebook.","metadata":{}},{"cell_type":"code","source":"test_samples = list(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\ntest_samples","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:53:50.693094Z","iopub.execute_input":"2025-04-15T10:53:50.693996Z","iopub.status.idle":"2025-04-15T10:53:50.706609Z","shell.execute_reply.started":"2025-04-15T10:53:50.693947Z","shell.execute_reply":"2025-04-15T10:53:50.705190Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_sub = pd.read_csv(\"/kaggle/input/birdclef-2023/sample_submission.csv\")\nsample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:54:12.791296Z","iopub.execute_input":"2025-04-15T10:54:12.791747Z","iopub.status.idle":"2025-04-15T10:54:12.898557Z","shell.execute_reply.started":"2025-04-15T10:54:12.791707Z","shell.execute_reply":"2025-04-15T10:54:12.897213Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"frame_limit_secs = 15 if sample_sub.shape[0] == 3 else None\nfor sample_filename in test_samples:\n    predict_for_sample(sample_filename, sample_sub, frame_limit_secs=15)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:58:26.618841Z","iopub.execute_input":"2025-04-15T10:58:26.619801Z","iopub.status.idle":"2025-04-15T10:58:38.342138Z","shell.execute_reply.started":"2025-04-15T10:58:26.619753Z","shell.execute_reply":"2025-04-15T10:58:38.340720Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:58:38.375911Z","iopub.execute_input":"2025-04-15T10:58:38.376383Z","iopub.status.idle":"2025-04-15T10:58:38.404923Z","shell.execute_reply.started":"2025-04-15T10:58:38.376315Z","shell.execute_reply":"2025-04-15T10:58:38.403409Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2025-04-15T10:59:23.665814Z","iopub.execute_input":"2025-04-15T10:59:23.666302Z","iopub.status.idle":"2025-04-15T10:59:23.688206Z","shell.execute_reply.started":"2025-04-15T10:59:23.666259Z","shell.execute_reply":"2025-04-15T10:59:23.686887Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}